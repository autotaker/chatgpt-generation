---
tags: Haskell ghc GarbageCollection
title: GHC/RTSのGCについて - 2
---
# GCの気持ちになって考える
先程の２つのベンチマークプログラムの振る舞いをGCの気持ちになって考えてみましょう。

## heap-light
```haskell
bench :: Int -> (a -> a) -> a -> a
bench n f i = go n i
    where
    go 0 !i = i
    go k !i = go (k-1) (f i)
{-# NOINLINE bench #-}
```
このプログラムは大量のヒープオブジェクトを生成しますが、それらはすべて、再帰関数が１段進むと死にます。したがって、nursery blocksがいっぱいになるたびにMinor GCが呼ばれますが、このとき、生きているヒープオブジェクトは現在の再帰関数`go`の引数`i`のみです。したがってGCはほとんど時間を消費しません。

## heap-heavy
```haskell
bench :: Int -> Int -> V.Vector Int
bench n i = V.unfoldrN n (\ !x -> Just (x, x+1)) i

main :: IO ()
main = do
    [n] <- fmap (map read) getArgs
    let k = 100000000 `div` n
    putStrLn $ "iteration: " ++ show k
    let go i !x | i == 0 = print $ V.last x
                | otherwise = traceMarker "tick" $ go (i - 1:: Int) (bench n i)
    go k (bench n 0)
```
このプログラムは長さ`n`の`V.Vector Int`を生成する部分がボトルネックとなります。このVectorは`n`個のInt型へのポインタを格納しています。また、Int型の値も`n`個あるので、`bench n i`はサイズ`n * 8` byteの大きなヒープオブジェクト一つと、サイズ16byteの小さなヒープオブジェクト`n`個を生成します。

`thread-scope`というプログラムを使ってGCがいつ起こっているかを見てみましょう。

### `n`=16kの時
このときは、GCは高速に動作し、全体の実行時間のおよそ25%を占めていました。
![Screenshot from 2019-01-29 16-25-20.png](https://qiita-image-store.s3.amazonaws.com/0/67228/cde7695e-567b-4f99-19a6-d1164d0a78d8.png)
このグラフの緑色が計算を行っている部分、赤色がGCを行っている部分となります。
縦線は`traceMarker "tick"`の呼び出しを表していて、すなわち再帰関数`go i x`が一回分進んだということになります。すなわち、`go i x`が何回か進むごとにGCが発生しています。この時生きているオブジェクトは現在生成中のvectorのみなので、たかだか3 * 8 * 16k = 384 k bytes のメモリだけがnursery blocksからGen-0にコピーされます。コピーされたヒープオブジェクトも次のGCが呼ばれる頃には死んでいるので、Gen-0のブロック数は一定のままで、Major GCはほとんど呼ばれません。

### `n`=128kのとき
このときはGCの実行時間は全体の75%を占めていました。すなわち`n`=16kの場合と比べると10倍近くGCが遅くなっています。
![Screenshot from 2019-01-29 16-45-35.png](https://qiita-image-store.s3.amazonaws.com/0/67228/5b11fa25-bc9a-c6ff-c4e4-e5888e490505.png)

この場合では`go i x`が一回進むごとにGCが２回走っていることがグラフから読み取れます。調べてみると、実行時間の長いほうがMinor GCで短いほうがMajor GCとなっています。
この理由を考察してましょう。
現在生成中のvectorのサイズは3 * 8 * 128 k = 3M bytes となっていて、これはnursery blocksのサイズの３倍あります。

再帰関数の一つ前のVectorがGen-1にいたと考えます。`traceMarker "tick"`の呼び出しのあとの最初のGC(Major GC)が走るとき、プログラムは次のvectorを生成している途中だと考えられます。Gen-1にいたvectorはもう死んでいるので回収されます。一方で新しく生成中のvectorは生きているので、nursery blockからGen-0 blockにコピーされます。nursery blockのサイズは1M bytesなので1M bytesのコピーが発生します。GCが終わった際、生きているGen-1オブジェクトはほとんどないはずなので、Major GCのしきい値は更新されません。

つぎのGC(Minor GC)が走る時もまた、プログラムはvectorの生成途中です。このとき、先程Gen-0にいたオブジェクトたちはまだ生きているのでGen-1に移動し、nursery blocksで新たに確保されたオブジェクトたちはGen-0に移動します。（もしかしたらEarly Promotionという仕組みによってGen-1に移動しているかもしれない）

このようにGCが起こるたびに大量のメモリコピーが発生しGCに時間がかかってしまいます。またMajor GCとMinor GCが交互に発生してしまっているのも良くないでしょう

### `n`=4096kの場合
![Screenshot from 2019-01-29 17-33-07.png](https://qiita-image-store.s3.amazonaws.com/0/67228/21d4d1e5-0e2d-c73c-7534-14bc49824e8e.png)

今回はvectorのサイズが極めて大きいので、再帰関数が呼び出されるたびにおよそ50回のMinor GCと1回のMajor GCが走っていました。GCの実行時間は全体の88%を占めています。`n`がこのあたりになるとGCの時間はあまり`n`に依存しなくなります。

vector自身はすぐにGen-1の住人になっているはずです。各minor GCでは生成したIntオブジェクトを次の世代に移すということが行われます。したがって、Gen-1のブロック数が次第に増大し、しばらくするとMajor GCが走ります。しかし、このMajor GCでもvectorは回収できず生き残るため、Major GCを起こすしきい値が徐々に大きくなってvectorのサイズくらいになります。この頃になると再帰の一つ前のvectorを回収できるので、ようやくGen-1のブロック数が減り、しきい値も小さくなります。したがって、このしきい値はvectorのサイズ程度に収束するでしょう。

### 考察
実行時間のグラフを振り返ってみましょう。
![消費メモリと実行時間(1).png](https://qiita-image-store.s3.amazonaws.com/0/67228/b598c87a-3cb2-b175-40e2-890d610127a8.png)
先程のグラフではGCとしてまとめていた部分を世代別の実行時間に分割しました。Gen-1の実行時間は`n`が256k以上になったあたりから一定でGen-0の実行時間が増えていることがわかります。これは以下のように説明できます。

* GCはnursery blocksがいっぱいになるたびに呼ばれ、GCが呼ばれるたびにnursery blocksは空になるので、(Minor GCの回数)+(Major GCの回数)は`n`の大きさによらず一定(今回だと1500回程度)です。
* 一時オブジェクトのサイズがnusery blocksのサイズを超えると、一時オブジェクトをほとんどすべて次の世代にコピーする必要が出てくるため、Minor GCに時間がかかるようになります。今回だとn = 1 M byte / 24 byte = 41.7 kあたりが境界線です。
* オブジェクトがGen-1で生き残るようになると、Gen-1ブロックのサイズ上限は動的に変化し、プログラムが実際に必要とするメモリ量くらいに収束します。したがってMajor GCにかかる時間はプログラム全体で確保されたメモリを解放する時間であり、それは`n`に依存しないのであまり実行時間は変化しません。
* 一方、全体のGC回数は一定なのでMinor GCの呼ばれる回数はMajor GCの回数が減るにつれて増えていきます。１回のMinor GCにかかる時間はnursery blockとGen-0ブロックのサイズはそれぞれたかだか1M byteなので、最悪でも定数時間（数ms程度)です。したがって、Minor GCにかかる時間も増加しますが、Minor GCの呼ばれる回数は1500回の上限があるのでその時間に収束します。

# GCのパラメータ調整
さて、大きな一時オブジェクトを大量に生成する場合、GCに時間がかかることがわかりました。このようなプログラムを高速に動作させたいときはRTSのパラメータを渡してGCの挙動を変えてやる必要があります。
今回の説明で理解できるパラメータは`+RTS -A<size>`です。これはnursery blocksのサイズを指定します。このサイズを考えられる一時オブジェクトのサイズよりも大きくしてやれば、一時オブジェクトがnurseryを卒業することなく死ぬため、GCの時間が劇的に早くなります。

先程の例で`n` = 1024kのとき、一時オブジェクトのサイズは24 M byteくらいになるので`-A32M`と指定してみましょう。

```bash
$ stack exec heap-heavy -- +RTS -ls -s -A32M -RTS  1024000
iteration: 97
1024000
   2,408,004,448 bytes allocated in the heap
     390,617,840 bytes copied during GC
      10,163,184 bytes maximum residency (2 sample(s))
         195,600 bytes maximum slop
               9 MB total memory in use (0 MB lost due to fragmentation)

                                     Tot time (elapsed)  Avg pause  Max pause
  Gen  0        47 colls,     0 par    0.252s   0.265s     0.0056s    0.0085s
  Gen  1         2 colls,     0 par    0.008s   0.008s     0.0039s    0.0045s

  INIT    time    0.000s  (  0.000s elapsed)
  MUT     time    0.409s  (  0.431s elapsed)
  GC      time    0.260s  (  0.273s elapsed)
  EXIT    time    0.000s  (  0.000s elapsed)
  Total   time    0.669s  (  0.705s elapsed)

  %GC     time       0.0%  (0.0% elapsed)

  Alloc rate    5,888,405,262 bytes per MUT second

  Productivity  61.1% of total user, 61.2% of total elapsed
```
実行時間は669msとなりました。全体で５倍程度、GCの時間だけだと10倍以上高速になっています。

他にもGCの挙動を変える様々なパラメータがあります。
[ドキュメント](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime_control.html#rts-options-to-control-the-garbage-collector)に色々書いてありますが、やはり**GCの気持ちにならないとよくわからない**のでGHCのソースとにらめっこしながらまた分かったら記事にまとめようと思います。

# 参考文献
* [GHC/Memory_Management](https://wiki.haskell.org/GHC/Memory_Management)
* [Parallel Generational-Copying Garbage Collection with a Block-Structured Heap (2008)](http://simonmar.github.io/bib/papers/parallel-gc.pdf): 概念を理解するのには役立ちますが、今のGHCとは実装が異なるようです。
* [ghc wiki:Commentary/Rts/Storage/GC](https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/GC): 実装よりのトピックがまとめてあります。
* [ghc/ghc](https://github.com/ghc/ghc):　ソース
